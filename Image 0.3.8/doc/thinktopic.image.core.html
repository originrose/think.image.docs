<!DOCTYPE html PUBLIC ""
    "">
<html><head><meta charset="UTF-8" /><title>thinktopic.image.core documentation</title><link rel="stylesheet" type="text/css" href="css/default.css" /><link rel="stylesheet" type="text/css" href="css/highlight.css" /><script type="text/javascript" src="js/highlight.min.js"></script><script type="text/javascript" src="js/jquery.min.js"></script><script type="text/javascript" src="js/page_effects.js"></script><script>hljs.initHighlightingOnLoad();</script></head><body><div id="header"><h2>Generated by <a href="https://github.com/weavejester/codox">Codox</a></h2><h1><a href="index.html"><span class="project-title"><span class="project-name">Image</span> <span class="project-version">0.3.8</span></span></a></h1></div><div class="sidebar primary"><h3 class="no-link"><span class="inner">Project</span></h3><ul class="index-link"><li class="depth-1 "><a href="index.html"><div class="inner">Index</div></a></li></ul><h3 class="no-link"><span class="inner">Topics</span></h3><ul><li class="depth-1 "><a href="intro.html"><div class="inner"><span>Introduction to image</span></div></a></li></ul><h3 class="no-link"><span class="inner">Namespaces</span></h3><ul><li class="depth-1"><div class="no-link"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>thinktopic</span></div></div></li><li class="depth-2"><div class="no-link"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>image</span></div></div></li><li class="depth-3 branch current"><a href="thinktopic.image.core.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>core</span></div></a></li><li class="depth-3"><a href="thinktopic.image.image-dictionary.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>image-dictionary</span></div></a></li></ul></div><div class="sidebar secondary"><h3><a href="#top"><span class="inner">Public Vars</span></a></h3><ul><li class="depth-1"><a href="thinktopic.image.core.html#var-a-shift"><div class="inner"><span>a-shift</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-alpha-blend-image"><div class="inner"><span>alpha-blend-image</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-b-shift"><div class="inner"><span>b-shift</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-bad-bounding-box.3F"><div class="inner"><span>bad-bounding-box?</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-BINS"><div class="inner"><span>BINS</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-blend"><div class="inner"><span>blend</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-blur"><div class="inner"><span>blur</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-blur-opencv-matrix"><div class="inner"><span>blur-opencv-matrix</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-bounding-box-from-single-channel-cv-matrix"><div class="inner"><span>bounding-box-from-single-channel-cv-matrix</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-bounding-box-height"><div class="inner"><span>bounding-box-height</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-bounding-box-seq"><div class="inner"><span>bounding-box-seq</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-bounding-box-seq-to-filtered-matrix-seq"><div class="inner"><span>bounding-box-seq-to-filtered-matrix-seq</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-bounding-box-to-opencv"><div class="inner"><span>bounding-box-to-opencv</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-bounding-box-width"><div class="inner"><span>bounding-box-width</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-build-signature-dictionary"><div class="inner"><span>build-signature-dictionary</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-build-sparse-coherency-map"><div class="inner"><span>build-sparse-coherency-map</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-clamp"><div class="inner"><span>clamp</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-clamp-mask-val"><div class="inner"><span>clamp-mask-val</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-color-int-to-unpacked"><div class="inner"><span>color-int-to-unpacked</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-color-signature"><div class="inner"><span>color-signature</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-color-unpacked-to-int"><div class="inner"><span>color-unpacked-to-int</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-count-pixel-groups"><div class="inner"><span>count-pixel-groups</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-create-feature-image-and-bounding-box"><div class="inner"><span>create-feature-image-and-bounding-box</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-create-nice-image-and-bounding-box"><div class="inner"><span>create-nice-image-and-bounding-box</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-create-nice-mat-and-bounding-box"><div class="inner"><span>create-nice-mat-and-bounding-box</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-create-opencv-allocation-system"><div class="inner"><span>create-opencv-allocation-system</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-create-opencv-matrix"><div class="inner"><span>create-opencv-matrix</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-denorm-color"><div class="inner"><span>denorm-color</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-dense-ccv-64-to-vector"><div class="inner"><span>dense-ccv-64-to-vector</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-dense-histogram-to-vector"><div class="inner"><span>dense-histogram-to-vector</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-double-round"><div class="inner"><span>double-round</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-double-to-int"><div class="inner"><span>double-to-int</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-draw-bounding-box"><div class="inner"><span>draw-bounding-box</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-ensure-valid-bbox"><div class="inner"><span>ensure-valid-bbox</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-feature-patches"><div class="inner"><span>feature-patches</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-filter-bounding-box-by-mask"><div class="inner"><span>filter-bounding-box-by-mask</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-find-bounding-box-from-edge-detect"><div class="inner"><span>find-bounding-box-from-edge-detect</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-find-content-bounding-box"><div class="inner"><span>find-content-bounding-box</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-find-scaled-content-bounding-box"><div class="inner"><span>find-scaled-content-bounding-box</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-fixed-sized-matrix"><div class="inner"><span>fixed-sized-matrix</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-g-shift"><div class="inner"><span>g-shift</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-generate-image-labels"><div class="inner"><span>generate-image-labels</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-get-aspect-from-width-height"><div class="inner"><span>get-aspect-from-width-height</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-get-ccv-and-color-signature"><div class="inner"><span>get-ccv-and-color-signature</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-get-height-from-aspect-width"><div class="inner"><span>get-height-from-aspect-width</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-get-image-mask-from-feature-image"><div class="inner"><span>get-image-mask-from-feature-image</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-get-image-writer"><div class="inner"><span>get-image-writer</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-get-larger-target-dims"><div class="inner"><span>get-larger-target-dims</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-get-masked-pixel"><div class="inner"><span>get-masked-pixel</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-get-matrix-ccv-and-color-signature"><div class="inner"><span>get-matrix-ccv-and-color-signature</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-get-opencv-image-mask-from-feature-image"><div class="inner"><span>get-opencv-image-mask-from-feature-image</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-get-pixels-outside-bbox"><div class="inner"><span>get-pixels-outside-bbox</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-get-scaled-bbox-and-mask"><div class="inner"><span>get-scaled-bbox-and-mask</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-get-shape-ccv-and-color-sig"><div class="inner"><span>get-shape-ccv-and-color-sig</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-get-width-from-aspect-height"><div class="inner"><span>get-width-from-aspect-height</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-grayscale"><div class="inner"><span>grayscale</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-grayscale-pixels"><div class="inner"><span>grayscale-pixels</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-image-label-search-locations"><div class="inner"><span>image-label-search-locations</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-image-requires-alpha-channel"><div class="inner"><span>image-requires-alpha-channel</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-image-signature"><div class="inner"><span>image-signature</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-image-to-opencv"><div class="inner"><span>image-to-opencv</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-img-.3Enormalized-grayscale-array"><div class="inner"><span>img-&gt;normalized-grayscale-array</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-int-pixels-to-rgb-byte-pixels"><div class="inner"><span>int-pixels-to-rgb-byte-pixels</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-int-pixels-to-rgba-byte-pixels"><div class="inner"><span>int-pixels-to-rgba-byte-pixels</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-int-round"><div class="inner"><span>int-round</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-int-subrect"><div class="inner"><span>int-subrect</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-int-to-mask"><div class="inner"><span>int-to-mask</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-is-same-size.3F"><div class="inner"><span>is-same-size?</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-is-valid-pixel-location.3F"><div class="inner"><span>is-valid-pixel-location?</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-mask-int-values"><div class="inner"><span>mask-int-values</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-mask-matrix-to-int-buffer"><div class="inner"><span>mask-matrix-to-int-buffer</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-mask-to-int"><div class="inner"><span>mask-to-int</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-maskbuf-to-image"><div class="inner"><span>maskbuf-to-image</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-maskbuf-to-packed-intbuf"><div class="inner"><span>maskbuf-to-packed-intbuf</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-matrix-to-scaled-matrix-seq"><div class="inner"><span>matrix-to-scaled-matrix-seq</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-max-vals"><div class="inner"><span>max-vals</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-min-vals"><div class="inner"><span>min-vals</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-mode-pixel"><div class="inner"><span>mode-pixel</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-norm-color"><div class="inner"><span>norm-color</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-normalize-patch"><div class="inner"><span>normalize-patch</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-offset-bbox"><div class="inner"><span>offset-bbox</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-opencv-allocate-matrix"><div class="inner"><span>opencv-allocate-matrix</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-opencv-bounding-box-submat"><div class="inner"><span>opencv-bounding-box-submat</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-opencv-edge-detect"><div class="inner"><span>opencv-edge-detect</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-opencv-ensure-rgb"><div class="inner"><span>opencv-ensure-rgb</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-opencv-gaussian-blur-image"><div class="inner"><span>opencv-gaussian-blur-image</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-opencv-grabcut"><div class="inner"><span>opencv-grabcut</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-opencv-ignore-matrix"><div class="inner"><span>opencv-ignore-matrix</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-opencv-masked-image-to-grayscale-and-mask"><div class="inner"><span>opencv-masked-image-to-grayscale-and-mask</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-opencv-mat-edge-detect"><div class="inner"><span>opencv-mat-edge-detect</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-opencv-mat-of-double"><div class="inner"><span>opencv-mat-of-double</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-opencv-mat-of-int"><div class="inner"><span>opencv-mat-of-int</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-opencv-mat-to-grayscale"><div class="inner"><span>opencv-mat-to-grayscale</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-opencv-mat-to-rgb-byte-pixels"><div class="inner"><span>opencv-mat-to-rgb-byte-pixels</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-opencv-matrix-allocation-system"><div class="inner"><span>opencv-matrix-allocation-system</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-opencv-matrix-and-mask-to-masked-matrix"><div class="inner"><span>opencv-matrix-and-mask-to-masked-matrix</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-opencv-matrix-context"><div class="inner"><span>opencv-matrix-context</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-opencv-matrix-grabcut"><div class="inner"><span>opencv-matrix-grabcut</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-opencv-matrix-to-byte-pixels"><div class="inner"><span>opencv-matrix-to-byte-pixels</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-opencv-matrix-to-double-array"><div class="inner"><span>opencv-matrix-to-double-array</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-opencv-mean-stddev"><div class="inner"><span>opencv-mean-stddev</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-opencv-normalize-matrix"><div class="inner"><span>opencv-normalize-matrix</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-opencv-normalized-matrix-to-image"><div class="inner"><span>opencv-normalized-matrix-to-image</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-opencv-patch-matrix-seq-from-matrix"><div class="inner"><span>opencv-patch-matrix-seq-from-matrix</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-opencv-release-all-matrixes"><div class="inner"><span>opencv-release-all-matrixes</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-opencv-release-matrix"><div class="inner"><span>opencv-release-matrix</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-opencv-resize-matrix"><div class="inner"><span>opencv-resize-matrix</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-opencv-rgba-matrix-to-patches"><div class="inner"><span>opencv-rgba-matrix-to-patches</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-opencv-submat"><div class="inner"><span>opencv-submat</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-opencv-submat-matrix-seq"><div class="inner"><span>opencv-submat-matrix-seq</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-opencv-to-image"><div class="inner"><span>opencv-to-image</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-opencv-to-int-pixels"><div class="inner"><span>opencv-to-int-pixels</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-opencv-type-to-image-type"><div class="inner"><span>opencv-type-to-image-type</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-pack-pixel"><div class="inner"><span>pack-pixel</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-packed-intbuf-to-maskbuf"><div class="inner"><span>packed-intbuf-to-maskbuf</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-pad-or-resize"><div class="inner"><span>pad-or-resize</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-pixel-location-to-index"><div class="inner"><span>pixel-location-to-index</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-print-image-array"><div class="inner"><span>print-image-array</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-quantize"><div class="inner"><span>quantize</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-quantize-px-range"><div class="inner"><span>quantize-px-range</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-quantize-range-pixels"><div class="inner"><span>quantize-range-pixels</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-r-shift"><div class="inner"><span>r-shift</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-range-quantize"><div class="inner"><span>range-quantize</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-relative-bbox"><div class="inner"><span>relative-bbox</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-rgb-byte-pixels-to-int-pixels"><div class="inner"><span>rgb-byte-pixels-to-int-pixels</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-rgba-byte-pixels-to-int-pixels"><div class="inner"><span>rgba-byte-pixels-to-int-pixels</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-rough-quantize-color"><div class="inner"><span>rough-quantize-color</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-sample-patches"><div class="inner"><span>sample-patches</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-sampled-patch-seq"><div class="inner"><span>sampled-patch-seq</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-scale-bbox"><div class="inner"><span>scale-bbox</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-scale-image"><div class="inner"><span>scale-image</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-scale-maskbuf"><div class="inner"><span>scale-maskbuf</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-scale-opencv-mat"><div class="inner"><span>scale-opencv-mat</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-shrink-bbox"><div class="inner"><span>shrink-bbox</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-sparse-ccv-64"><div class="inner"><span>sparse-ccv-64</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-sparse-ccv-64-to-dense-normalized-ccv-64"><div class="inner"><span>sparse-ccv-64-to-dense-normalized-ccv-64</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-sparse-ccv-from-quantized-image-pixels"><div class="inner"><span>sparse-ccv-from-quantized-image-pixels</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-sparse-histogram-64"><div class="inner"><span>sparse-histogram-64</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-sparse-histogram-64-to-dense-histogram-64"><div class="inner"><span>sparse-histogram-64-to-dense-histogram-64</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-sparse-histogram-from-pixels"><div class="inner"><span>sparse-histogram-from-pixels</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-square-image"><div class="inner"><span>square-image</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-square-matrix"><div class="inner"><span>square-matrix</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-stats"><div class="inner"><span>stats</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-to-bounding-box-from-flattened"><div class="inner"><span>to-bounding-box-from-flattened</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-unpack-pixel"><div class="inner"><span>unpack-pixel</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-widen-bounding-box"><div class="inner"><span>widen-bounding-box</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-with-unpacked-pixel"><div class="inner"><span>with-unpacked-pixel</span></div></a></li><li class="depth-1"><a href="thinktopic.image.core.html#var-write-image-to-stream"><div class="inner"><span>write-image-to-stream</span></div></a></li></ul></div><div class="namespace-docs" id="content"><h1 class="anchor" id="top">thinktopic.image.core</h1><div class="doc"><pre class="plaintext"></pre></div><div class="public anchor" id="var-a-shift"><h3>a-shift</h3><div class="usage"></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-alpha-blend-image"><h3>alpha-blend-image</h3><div class="usage"><code>(alpha-blend-image img blend-color)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-b-shift"><h3>b-shift</h3><div class="usage"></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-bad-bounding-box.3F"><h3>bad-bounding-box?</h3><div class="usage"><code>(bad-bounding-box? bbox width height)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-BINS"><h3>BINS</h3><div class="usage"></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-blend"><h3>blend</h3><h4 class="type">macro</h4><div class="usage"><code>(blend alpha val one-minus-alpha dest)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-blur"><h3>blur</h3><div class="usage"><code>(blur img)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-blur-opencv-matrix"><h3>blur-opencv-matrix</h3><div class="usage"><code>(blur-opencv-matrix input-mat)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-bounding-box-from-single-channel-cv-matrix"><h3>bounding-box-from-single-channel-cv-matrix</h3><div class="usage"><code>(bounding-box-from-single-channel-cv-matrix cv-mat)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-bounding-box-height"><h3>bounding-box-height</h3><div class="usage"><code>(bounding-box-height [x-min y-min x-max y-max])</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-bounding-box-seq"><h3>bounding-box-seq</h3><div class="usage"><code>(bounding-box-seq width height target-dim)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-bounding-box-seq-to-filtered-matrix-seq"><h3>bounding-box-seq-to-filtered-matrix-seq</h3><div class="usage"><code>(bounding-box-seq-to-filtered-matrix-seq bounding-box-seq input-matrix mask-matrix &amp; {:keys [filter-threshold], :or {filter-threshold 250}})</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-bounding-box-to-opencv"><h3>bounding-box-to-opencv</h3><div class="usage"><code>(bounding-box-to-opencv bounding-box)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-bounding-box-width"><h3>bounding-box-width</h3><div class="usage"><code>(bounding-box-width [x-min y-min x-max y-max])</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-build-signature-dictionary"><h3>build-signature-dictionary</h3><div class="usage"><code>(build-signature-dictionary patches k iters)</code><code>(build-signature-dictionary patches k)</code></div><div class="doc"><pre class="plaintext">Run k-means using the rows of the matrix as input vectors
used on result of sampled-patch-seq</pre></div></div><div class="public anchor" id="var-build-sparse-coherency-map"><h3>build-sparse-coherency-map</h3><div class="usage"><code>(build-sparse-coherency-map counted-pixel-groups threshold-count)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-clamp"><h3>clamp</h3><div class="usage"><code>(clamp item min-val max-val)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-clamp-mask-val"><h3>clamp-mask-val</h3><h4 class="type">macro</h4><div class="usage"><code>(clamp-mask-val mval)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-color-int-to-unpacked"><h3>color-int-to-unpacked</h3><div class="usage"><code>(color-int-to-unpacked px shift-amount)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-color-signature"><h3>color-signature</h3><div class="usage"><code>(color-signature source-image &amp; {:keys [num-centroids mask-ints], :or {num-centroids 10}})</code></div><div class="doc"><pre class="plaintext">K-means on the rgb triplets from an image.  Then sort the centroids such that
the centroid with the highest number of items is first.  Operates from an integer
packed color buffer.</pre></div></div><div class="public anchor" id="var-color-unpacked-to-int"><h3>color-unpacked-to-int</h3><div class="usage"><code>(color-unpacked-to-int bt shift-amount)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-count-pixel-groups"><h3>count-pixel-groups</h3><div class="usage"><code>(count-pixel-groups labels pixels groups)</code></div><div class="doc"><pre class="plaintext">returns labels mapped to colors and count of pixels in label
</pre></div></div><div class="public anchor" id="var-create-feature-image-and-bounding-box"><h3>create-feature-image-and-bounding-box</h3><div class="usage"><code>(create-feature-image-and-bounding-box img &amp; [bbox square-image-size])</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-create-nice-image-and-bounding-box"><h3>create-nice-image-and-bounding-box</h3><div class="usage"><code>(create-nice-image-and-bounding-box img &amp; [bbox widen-threshold])</code></div><div class="doc"><pre class="plaintext">returns [nice-image nice-bbox]
</pre></div></div><div class="public anchor" id="var-create-nice-mat-and-bounding-box"><h3>create-nice-mat-and-bounding-box</h3><div class="usage"><code>(create-nice-mat-and-bounding-box img-mat bounding-box &amp; {:keys [widen-constant], :or {widen-constant 1.3}})</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-create-opencv-allocation-system"><h3>create-opencv-allocation-system</h3><div class="usage"><code>(create-opencv-allocation-system)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-create-opencv-matrix"><h3>create-opencv-matrix</h3><div class="usage"><code>(create-opencv-matrix prototype)</code><code>(create-opencv-matrix prototype mat-type)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-denorm-color"><h3>denorm-color</h3><div class="usage"><code>(denorm-color c)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-dense-ccv-64-to-vector"><h3>dense-ccv-64-to-vector</h3><div class="usage"><code>(dense-ccv-64-to-vector dense-ccv-64)</code></div><div class="doc"><pre class="plaintext">Returns a core.matrix array containing just the values without
color labels.  In order for these vectors to be comparable we rely
on the fact that the dense mapping is sorted by color.</pre></div></div><div class="public anchor" id="var-dense-histogram-to-vector"><h3>dense-histogram-to-vector</h3><div class="usage"><code>(dense-histogram-to-vector histo)</code></div><div class="doc"><pre class="plaintext">Create a vector of the histogram of colors
</pre></div></div><div class="public anchor" id="var-double-round"><h3>double-round</h3><div class="usage"><code>(double-round number)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-double-to-int"><h3>double-to-int</h3><div class="usage"><code>(double-to-int dval)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-draw-bounding-box"><h3>draw-bounding-box</h3><div class="usage"><code>(draw-bounding-box img bbox int-color)</code></div><div class="doc"><pre class="plaintext">Given an input image, draw a bounding box in the color
defined by a packed int color.  Return a new image</pre></div></div><div class="public anchor" id="var-ensure-valid-bbox"><h3>ensure-valid-bbox</h3><div class="usage"><code>(ensure-valid-bbox bbox width height)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-feature-patches"><h3>feature-patches</h3><div class="usage"><code>(feature-patches img n w h)</code></div><div class="doc"><pre class="plaintext">Return a matrix of w*h rows and n columns of wxh patches from within the image
</pre></div></div><div class="public anchor" id="var-filter-bounding-box-by-mask"><h3>filter-bounding-box-by-mask</h3><div class="usage"><code>(filter-bounding-box-by-mask bounding-box mask-mat threshold)</code></div><div class="doc"><pre class="plaintext">return the bounding box if the mean of the matrix within the
bounding box is above a given threshold.  False otherwise.  Expects
a single channel mask matrix</pre></div></div><div class="public anchor" id="var-find-bounding-box-from-edge-detect"><h3>find-bounding-box-from-edge-detect</h3><div class="usage"><code>(find-bounding-box-from-edge-detect original-image)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-find-content-bounding-box"><h3>find-content-bounding-box</h3><div class="usage"><code>(find-content-bounding-box original-image)</code></div><div class="doc"><pre class="plaintext">Finding the content bounding box is a complex procedure.  We first
find a rough cut using edge detect.  We then find a more precise cut
using grabcut and the bounding box found through the rough cut.
Finally we scale it back up to full size and go on with our lives</pre></div></div><div class="public anchor" id="var-find-scaled-content-bounding-box"><h3>find-scaled-content-bounding-box</h3><div class="usage"><code>(find-scaled-content-bounding-box original-image &amp; {:keys [scale-pixels bounding-box], :or {scale-pixels 400}})</code></div><div class="doc"><pre class="plaintext">Find scaled content and bounding box passing in an optional bounding box override
</pre></div></div><div class="public anchor" id="var-fixed-sized-matrix"><h3>fixed-sized-matrix</h3><div class="usage"><code>(fixed-sized-matrix source-matrix bbox background-color dest-width dest-height &amp; {:keys [widen-ratio]})</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-g-shift"><h3>g-shift</h3><div class="usage"></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-generate-image-labels"><h3>generate-image-labels</h3><div class="usage"><code>(generate-image-labels pixels width height)</code></div><div class="doc"><pre class="plaintext">returns an array of labels and a union find struct containing
information about the label unions found during labelling</pre></div></div><div class="public anchor" id="var-get-aspect-from-width-height"><h3>get-aspect-from-width-height</h3><div class="usage"><code>(get-aspect-from-width-height width height)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-get-ccv-and-color-signature"><h3>get-ccv-and-color-signature</h3><div class="usage"><code>(get-ccv-and-color-signature content-image &amp; [ccv-threshold mask-packed-ints content-bbox])</code></div><div class="doc"><pre class="plaintext">returns [ccv color-sig]
</pre></div></div><div class="public anchor" id="var-get-height-from-aspect-width"><h3>get-height-from-aspect-width</h3><div class="usage"><code>(get-height-from-aspect-width aspect width)</code></div><div class="doc"><pre class="plaintext">aspect defined as width/height
</pre></div></div><div class="public anchor" id="var-get-image-mask-from-feature-image"><h3>get-image-mask-from-feature-image</h3><div class="usage"><code>(get-image-mask-from-feature-image feature-image feature-bbox dest-image dest-bbox)</code></div><div class="doc"><pre class="plaintext">Get an image mask from the feature image.  The result is an image
alpha of 255 in the mask locations</pre></div></div><div class="public anchor" id="var-get-image-writer"><h3>get-image-writer</h3><div class="usage"><code>(get-image-writer format-name)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-get-larger-target-dims"><h3>get-larger-target-dims</h3><div class="usage"><code>(get-larger-target-dims src-width src-height dest-aspect)</code></div><div class="doc"><pre class="plaintext">Get the target width,height if you want a new image with the
destination aspect ratio by enlarging (no cropping)</pre></div></div><div class="public anchor" id="var-get-masked-pixel"><h3>get-masked-pixel</h3><div class="usage"><code>(get-masked-pixel color)</code></div><div class="doc"><pre class="plaintext">Make sure alpha is always 1.  This allows writing out the image and checking
the result but still ensures we are ignoring alpha which should have been multiplied
through by this stage of the pipeline</pre></div></div><div class="public anchor" id="var-get-matrix-ccv-and-color-signature"><h3>get-matrix-ccv-and-color-signature</h3><div class="usage"><code>(get-matrix-ccv-and-color-signature masked-feature-image feature-bbox &amp; {:keys [ccv-threshold], :or {ccv-threshold 0.01}})</code></div><div class="doc"><pre class="plaintext">Takes an rgba matrix where the mask is contained in the alpha
channel.  Returns [color-coherence-vector color-signature].</pre></div></div><div class="public anchor" id="var-get-opencv-image-mask-from-feature-image"><h3>get-opencv-image-mask-from-feature-image</h3><div class="usage"><code>(get-opencv-image-mask-from-feature-image feature-image feature-bbox dest-image dest-bbox)</code></div><div class="doc"><pre class="plaintext">Get an image mask from the feature image.  The result is an image
with alpha of 255 in the mask locations</pre></div></div><div class="public anchor" id="var-get-pixels-outside-bbox"><h3>get-pixels-outside-bbox</h3><div class="usage"><code>(get-pixels-outside-bbox original-mat bbox)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-get-scaled-bbox-and-mask"><h3>get-scaled-bbox-and-mask</h3><div class="usage"><code>(get-scaled-bbox-and-mask scaled-mat scaled-bounding-box)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-get-shape-ccv-and-color-sig"><h3>get-shape-ccv-and-color-sig</h3><div class="usage"><code>(get-shape-ccv-and-color-sig content-image bbox &amp; {:keys [ccv-threshold shape-mask-dim], :or {ccv-threshold 0.01, shape-mask-dim 64}})</code></div><div class="doc"><pre class="plaintext">Get ccv, color sig and shape vector.  Shape mask dim refers to the dimension
of the shape mask image, not of the final shape vector.
return [ccv sig mask-vec]</pre></div></div><div class="public anchor" id="var-get-width-from-aspect-height"><h3>get-width-from-aspect-height</h3><div class="usage"><code>(get-width-from-aspect-height aspect height)</code></div><div class="doc"><pre class="plaintext">aspect defined as width/height
</pre></div></div><div class="public anchor" id="var-grayscale"><h3>grayscale</h3><div class="usage"><code>(grayscale img)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-grayscale-pixels"><h3>grayscale-pixels</h3><div class="usage"><code>(grayscale-pixels img)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-image-label-search-locations"><h3>image-label-search-locations</h3><div class="usage"></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-image-requires-alpha-channel"><h3>image-requires-alpha-channel</h3><div class="usage"><code>(image-requires-alpha-channel img)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-image-signature"><h3>image-signature</h3><div class="usage"><code>(image-signature img n-patches patch-width patch-height feature-dictionary)</code></div><div class="doc"><pre class="plaintext">Given an image and a signature dictionary, return a texture
signature which is a set of dot products of random patches of the
image with patches in the feature dictionary.  Each image patch is
dotted with every dictionary feature vector and the absolute values
are summed.  This final sequence is then normalized</pre></div></div><div class="public anchor" id="var-image-to-opencv"><h3>image-to-opencv</h3><div class="usage"><code>(image-to-opencv image &amp; {:keys [keep-alpha]})</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-img-.3Enormalized-grayscale-array"><h3>img-&gt;normalized-grayscale-array</h3><div class="usage"><code>(img-&gt;normalized-grayscale-array img)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-int-pixels-to-rgb-byte-pixels"><h3>int-pixels-to-rgb-byte-pixels</h3><div class="usage"><code>(int-pixels-to-rgb-byte-pixels pixels)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-int-pixels-to-rgba-byte-pixels"><h3>int-pixels-to-rgba-byte-pixels</h3><div class="usage"><code>(int-pixels-to-rgba-byte-pixels pixels)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-int-round"><h3>int-round</h3><div class="usage"><code>(int-round dval)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-int-subrect"><h3>int-subrect</h3><div class="usage"><code>(int-subrect source width height bbox)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-int-to-mask"><h3>int-to-mask</h3><div class="usage"><code>(int-to-mask item idx)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-is-same-size.3F"><h3>is-same-size?</h3><div class="usage"><code>(is-same-size? bbox width height)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-is-valid-pixel-location.3F"><h3>is-valid-pixel-location?</h3><div class="usage"><code>(is-valid-pixel-location? x y width height)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-mask-int-values"><h3>mask-int-values</h3><div class="usage"><code>(mask-int-values int-vals mask)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-mask-matrix-to-int-buffer"><h3>mask-matrix-to-int-buffer</h3><div class="usage"><code>(mask-matrix-to-int-buffer matrix)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-mask-to-int"><h3>mask-to-int</h3><div class="usage"><code>(mask-to-int mask idx)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-maskbuf-to-image"><h3>maskbuf-to-image</h3><div class="usage"><code>(maskbuf-to-image pixbuf width height)</code></div><div class="doc"><pre class="plaintext">Given a mask buffer create an image from it
</pre></div></div><div class="public anchor" id="var-maskbuf-to-packed-intbuf"><h3>maskbuf-to-packed-intbuf</h3><div class="usage"><code>(maskbuf-to-packed-intbuf maskbuf)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-matrix-to-scaled-matrix-seq"><h3>matrix-to-scaled-matrix-seq</h3><div class="usage"><code>(matrix-to-scaled-matrix-seq input-mat input-size-seq)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-max-vals"><h3>max-vals</h3><div class="usage"><code>(max-vals [x y] [xx yy])</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-min-vals"><h3>min-vals</h3><div class="usage"><code>(min-vals [x y] [xx yy])</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-mode-pixel"><h3>mode-pixel</h3><div class="usage"><code>(mode-pixel s)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-norm-color"><h3>norm-color</h3><div class="usage"><code>(norm-color c)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-normalize-patch"><h3>normalize-patch</h3><div class="usage"><code>(normalize-patch patch)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-offset-bbox"><h3>offset-bbox</h3><div class="usage"><code>(offset-bbox bbox x-offset y-offset)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-opencv-allocate-matrix"><h3>opencv-allocate-matrix</h3><div class="usage"><code>(opencv-allocate-matrix)</code><code>(opencv-allocate-matrix height width type)</code><code>(opencv-allocate-matrix height width type init-scalar)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-opencv-bounding-box-submat"><h3>opencv-bounding-box-submat</h3><div class="usage"><code>(opencv-bounding-box-submat source-matrix bounding-box)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-opencv-edge-detect"><h3>opencv-edge-detect</h3><div class="usage"><code>(opencv-edge-detect img &amp; {:keys [low-threshold ratio kernel-size], :or {low-threshold 100, ratio 3, kernel-size 3}})</code></div><div class="doc"><pre class="plaintext">Returns a single channel opencv matrix where 0 values mean no edge
and values of 255 mean edge</pre></div></div><div class="public anchor" id="var-opencv-ensure-rgb"><h3>opencv-ensure-rgb</h3><div class="usage"><code>(opencv-ensure-rgb img-mat)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-opencv-gaussian-blur-image"><h3>opencv-gaussian-blur-image</h3><div class="usage"><code>(opencv-gaussian-blur-image img &amp; {:keys [kernel-width kernel-height], :or {kernel-width 11, kernel-height 11}})</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-opencv-grabcut"><h3>opencv-grabcut</h3><div class="usage"><code>(opencv-grabcut img bbox)</code></div><div class="doc"><pre class="plaintext">Used for foreground detection.  Returns a byte mask buffer where
anything nonzero means foreground</pre></div></div><div class="public anchor" id="var-opencv-ignore-matrix"><h3>opencv-ignore-matrix</h3><div class="usage"><code>(opencv-ignore-matrix item)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-opencv-masked-image-to-grayscale-and-mask"><h3>opencv-masked-image-to-grayscale-and-mask</h3><div class="usage"><code>(opencv-masked-image-to-grayscale-and-mask input)</code></div><div class="doc"><pre class="plaintext">Take rgba image premultiplied and produce an rgb image
that is postmultiplied.  This will in effect blacken out pixels
that have alpha of 0.</pre></div></div><div class="public anchor" id="var-opencv-mat-edge-detect"><h3>opencv-mat-edge-detect</h3><div class="usage"><code>(opencv-mat-edge-detect img-mat &amp; {:keys [low-threshold ratio kernel-size], :or {low-threshold 100, ratio 3, kernel-size 3}})</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-opencv-mat-of-double"><h3>opencv-mat-of-double</h3><div class="usage"><code>(opencv-mat-of-double)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-opencv-mat-of-int"><h3>opencv-mat-of-int</h3><div class="usage"><code>(opencv-mat-of-int data)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-opencv-mat-to-grayscale"><h3>opencv-mat-to-grayscale</h3><div class="usage"><code>(opencv-mat-to-grayscale img-mat)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-opencv-mat-to-rgb-byte-pixels"><h3>opencv-mat-to-rgb-byte-pixels</h3><div class="usage"><code>(opencv-mat-to-rgb-byte-pixels mat)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-opencv-matrix-allocation-system"><h3>opencv-matrix-allocation-system</h3><h4 class="dynamic">dynamic</h4><div class="usage"></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-opencv-matrix-and-mask-to-masked-matrix"><h3>opencv-matrix-and-mask-to-masked-matrix</h3><div class="usage"><code>(opencv-matrix-and-mask-to-masked-matrix image mask)</code></div><div class="doc"><pre class="plaintext">Takes an rgb image, a mask and a background rgb color.  Produces
and rgba matrix with the masked-out pixels transparent black (all zeros)</pre></div></div><div class="public anchor" id="var-opencv-matrix-context"><h3>opencv-matrix-context</h3><h4 class="type">macro</h4><div class="usage"><code>(opencv-matrix-context &amp; body)</code></div><div class="doc"><pre class="plaintext">All matrixes allocated within this context will be released at the
exit from this context</pre></div></div><div class="public anchor" id="var-opencv-matrix-grabcut"><h3>opencv-matrix-grabcut</h3><div class="usage"><code>(opencv-matrix-grabcut img-mat bbox)</code></div><div class="doc"><pre class="plaintext">Used for foreground detection.  Returns a byte mask buffer where
anything nonzero means foreground</pre></div></div><div class="public anchor" id="var-opencv-matrix-to-byte-pixels"><h3>opencv-matrix-to-byte-pixels</h3><div class="usage"><code>(opencv-matrix-to-byte-pixels matrix)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-opencv-matrix-to-double-array"><h3>opencv-matrix-to-double-array</h3><div class="usage"><code>(opencv-matrix-to-double-array matrix)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-opencv-mean-stddev"><h3>opencv-mean-stddev</h3><div class="usage"><code>(opencv-mean-stddev image)</code></div><div class="doc"><pre class="plaintext">Returns [[means] [stddevs]] of doubles for each channel of the image
</pre></div></div><div class="public anchor" id="var-opencv-normalize-matrix"><h3>opencv-normalize-matrix</h3><div class="usage"><code>(opencv-normalize-matrix input)</code></div><div class="doc"><pre class="plaintext">Expects a single channel matrix and produces a normalized result
where normalized means (x - mean)/stddev</pre></div></div><div class="public anchor" id="var-opencv-normalized-matrix-to-image"><h3>opencv-normalized-matrix-to-image</h3><div class="usage"><code>(opencv-normalized-matrix-to-image norm-mat)</code></div><div class="doc"><pre class="plaintext">Utility method to view a normalized matrix
</pre></div></div><div class="public anchor" id="var-opencv-patch-matrix-seq-from-matrix"><h3>opencv-patch-matrix-seq-from-matrix</h3><div class="usage"><code>(opencv-patch-matrix-seq-from-matrix input-mat final-patch-size n-per-size input-size-seq)</code></div><div class="doc"><pre class="plaintext">Returns a sequence of patches from a matrix.  Running through the
input sizes and scaling them down to the final size, this returns
(* (count input-size-seq) n-per-size) patches per matrix.  A patch is
a normalized matrix (mean subtracted and divided by stddev).  Input mat
is expected to be an ARGB matrix with the mask in the alpha channel</pre></div></div><div class="public anchor" id="var-opencv-release-all-matrixes"><h3>opencv-release-all-matrixes</h3><div class="usage"><code>(opencv-release-all-matrixes alloc-system)</code><code>(opencv-release-all-matrixes)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-opencv-release-matrix"><h3>opencv-release-matrix</h3><div class="usage"><code>(opencv-release-matrix item)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-opencv-resize-matrix"><h3>opencv-resize-matrix</h3><div class="usage"><code>(opencv-resize-matrix input target-width target-height)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-opencv-rgba-matrix-to-patches"><h3>opencv-rgba-matrix-to-patches</h3><div class="usage"><code>(opencv-rgba-matrix-to-patches input-mat patch-size num-patches)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-opencv-submat"><h3>opencv-submat</h3><div class="usage"><code>(opencv-submat source-matrix dimensions)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-opencv-submat-matrix-seq"><h3>opencv-submat-matrix-seq</h3><div class="usage"><code>(opencv-submat-matrix-seq input-mat submat-size num-patches)</code></div><div class="doc"><pre class="plaintext">Generates n square patches from an input matrix.  Returns nil of the submat size
is greater than or equal to the input matrix size</pre></div></div><div class="public anchor" id="var-opencv-to-image"><h3>opencv-to-image</h3><div class="usage"><code>(opencv-to-image matrix)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-opencv-to-int-pixels"><h3>opencv-to-int-pixels</h3><div class="usage"><code>(opencv-to-int-pixels matrix)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-opencv-type-to-image-type"><h3>opencv-type-to-image-type</h3><div class="usage"><code>(opencv-type-to-image-type opencv-mat-type)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-pack-pixel"><h3>pack-pixel</h3><div class="usage"><code>(pack-pixel r g b a)</code><code>(pack-pixel data)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-packed-intbuf-to-maskbuf"><h3>packed-intbuf-to-maskbuf</h3><div class="usage"><code>(packed-intbuf-to-maskbuf intbuf)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-pad-or-resize"><h3>pad-or-resize</h3><div class="usage"><code>(pad-or-resize img dest-width bbox background-color)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-pixel-location-to-index"><h3>pixel-location-to-index</h3><div class="usage"><code>(pixel-location-to-index x y width)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-print-image-array"><h3>print-image-array</h3><div class="usage"><code>(print-image-array image width height)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-quantize"><h3>quantize</h3><div class="usage"><code>(quantize img n-colors)</code></div><div class="doc"><pre class="plaintext">Quantize an image to n colors.  The underlying filter builds an octree to determine
a set of colors that will produce minimal distortion, but these will be different
colors for each image.</pre></div></div><div class="public anchor" id="var-quantize-px-range"><h3>quantize-px-range</h3><div class="usage"><code>(quantize-px-range px range)</code></div><div class="doc"><pre class="plaintext">Quantize 32-bit ARGB(8888) pixels to RGB(222) format.  On a little-endian machine
this means we use the right most 6 bits </pre></div></div><div class="public anchor" id="var-quantize-range-pixels"><h3>quantize-range-pixels</h3><div class="usage"><code>(quantize-range-pixels pixels quant-range)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-r-shift"><h3>r-shift</h3><div class="usage"></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-range-quantize"><h3>range-quantize</h3><div class="usage"><code>(range-quantize img range)</code></div><div class="doc"><pre class="plaintext">quantize the image so that each channel only has range integer precision.
So if range is 4, you are only using 2 bits per channel.
  If range is 8, you are using 3 bits per channel</pre></div></div><div class="public anchor" id="var-relative-bbox"><h3>relative-bbox</h3><div class="usage"><code>(relative-bbox coord-bbox bbox)</code></div><div class="doc"><pre class="plaintext">Given two bounding boxes in an identical coordinate space
, return a new box which is the second box
described in the coordinate space defined by the first box</pre></div></div><div class="public anchor" id="var-rgb-byte-pixels-to-int-pixels"><h3>rgb-byte-pixels-to-int-pixels</h3><div class="usage"><code>(rgb-byte-pixels-to-int-pixels byte-pixels)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-rgba-byte-pixels-to-int-pixels"><h3>rgba-byte-pixels-to-int-pixels</h3><div class="usage"><code>(rgba-byte-pixels-to-int-pixels byte-pixels)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-rough-quantize-color"><h3>rough-quantize-color</h3><div class="usage"><code>(rough-quantize-color c range)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-sample-patches"><h3>sample-patches</h3><div class="usage"><code>(sample-patches pixels n w h)</code></div><div class="doc"><pre class="plaintext">Sample n patches of size w x h at random locations.
</pre></div></div><div class="public anchor" id="var-sampled-patch-seq"><h3>sampled-patch-seq</h3><div class="usage"><code>(sampled-patch-seq image-seq n w h)</code></div><div class="doc"><pre class="plaintext">Returns a seq of n normalized, grayscale patches per image of size w x h.
</pre></div></div><div class="public anchor" id="var-scale-bbox"><h3>scale-bbox</h3><div class="usage"><code>(scale-bbox bbox scale)</code></div><div class="doc"><pre class="plaintext">Scale a bounding box such that the scaled box
will fit the same relative locations on the scaled image</pre></div></div><div class="public anchor" id="var-scale-image"><h3>scale-image</h3><div class="usage"><code>(scale-image img bounding-box new-dim)</code></div><div class="doc"><pre class="plaintext">Scale an image preserving aspect ratio such that the largest
dimension is now new-dim.  Returns [scaled-img scaled-bounding-box]</pre></div></div><div class="public anchor" id="var-scale-maskbuf"><h3>scale-maskbuf</h3><div class="usage"><code>(scale-maskbuf maskbuf width height new-dim)</code></div><div class="doc"><pre class="plaintext">Scale a mask buffer returning a new mask buffer.  Takes the image
width and height intended for the mask buffer</pre></div></div><div class="public anchor" id="var-scale-opencv-mat"><h3>scale-opencv-mat</h3><div class="usage"><code>(scale-opencv-mat img-mat bounding-box new-dim)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-shrink-bbox"><h3>shrink-bbox</h3><div class="usage"><code>(shrink-bbox bbox)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-sparse-ccv-64"><h3>sparse-ccv-64</h3><div class="usage"><code>(sparse-ccv-64 img threshold)</code></div><div class="doc"><pre class="plaintext">Computes a color coherence vector for an image after quantizing to
64 colors. The threshold is used to specify what percent of an image
(how many pixels) must a blob be in order to be considered coherent.
Returns map of color [coh incoh] where item counts are in pixels
along with the pixel count</pre></div></div><div class="public anchor" id="var-sparse-ccv-64-to-dense-normalized-ccv-64"><h3>sparse-ccv-64-to-dense-normalized-ccv-64</h3><div class="usage"><code>(sparse-ccv-64-to-dense-normalized-ccv-64 sparse-color-coherency-retval)</code></div><div class="doc"><pre class="plaintext">Takes the spare ccv result and returns a vector, sorted by color
from least to largest.  Colors are all negative because highest two
bytes (alpha) are all 0xFF.  This result is sorted because the BINS
var is sorted.</pre></div></div><div class="public anchor" id="var-sparse-ccv-from-quantized-image-pixels"><h3>sparse-ccv-from-quantized-image-pixels</h3><div class="usage"><code>(sparse-ccv-from-quantized-image-pixels pixels width height threshold)</code></div><div class="doc"><pre class="plaintext">Given a preprocessed array of pixels, produce a sparse ccv map of
color to [coh, incoh] with n-pixels*threshold deciding coherency</pre></div></div><div class="public anchor" id="var-sparse-histogram-64"><h3>sparse-histogram-64</h3><div class="usage"><code>(sparse-histogram-64 img)</code></div><div class="doc"><pre class="plaintext">Create a sparse histogram of colors in an image
</pre></div></div><div class="public anchor" id="var-sparse-histogram-64-to-dense-histogram-64"><h3>sparse-histogram-64-to-dense-histogram-64</h3><div class="usage"><code>(sparse-histogram-64-to-dense-histogram-64 sparse-histogram-retval)</code></div><div class="doc"><pre class="plaintext">sparse-unnormalized to dense normalized
</pre></div></div><div class="public anchor" id="var-sparse-histogram-from-pixels"><h3>sparse-histogram-from-pixels</h3><div class="usage"><code>(sparse-histogram-from-pixels pixels width height)</code></div><div class="doc"><pre class="plaintext">Create a sparse histogram map of color-&gt;pixel-count from integer pixel data
</pre></div></div><div class="public anchor" id="var-square-image"><h3>square-image</h3><div class="usage"><code>(square-image source-image bbox background-color img-dim)</code></div><div class="doc"><pre class="plaintext">given an input image and a bounding box, return an output image
with the background color (integer) and the content described by the bbox
centered.  Finally resize image to size desired</pre></div></div><div class="public anchor" id="var-square-matrix"><h3>square-matrix</h3><div class="usage"><code>(square-matrix source-matrix bbox background-color img-dim)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-stats"><h3>stats</h3><div class="usage"><code>(stats ary)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-to-bounding-box-from-flattened"><h3>to-bounding-box-from-flattened</h3><div class="usage"><code>(to-bounding-box-from-flattened data)</code></div><div class="doc"><pre class="plaintext">Create a bounding box from a list of 4 doubles (the result of
flattening)</pre></div></div><div class="public anchor" id="var-unpack-pixel"><h3>unpack-pixel</h3><div class="usage"><code>(unpack-pixel px)</code></div><div class="doc"><pre class="plaintext">Returns [R G B A].  Note that java does not have unsigned types
so some of these may be negative</pre></div></div><div class="public anchor" id="var-widen-bounding-box"><h3>widen-bounding-box</h3><div class="usage"><code>(widen-bounding-box bbox width height multiplier)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-with-unpacked-pixel"><h3>with-unpacked-pixel</h3><h4 class="type">macro</h4><div class="usage"><code>(with-unpacked-pixel px &amp; body)</code></div><div class="doc"><pre class="plaintext">work with pixel data in rgba variables
</pre></div></div><div class="public anchor" id="var-write-image-to-stream"><h3>write-image-to-stream</h3><div class="usage"><code>(write-image-to-stream buffered-image format output-stream &amp; {:keys [lossy-quality], :or {lossy-quality 0.95}})</code></div><div class="doc"><pre class="plaintext"></pre></div></div></div></body></html>